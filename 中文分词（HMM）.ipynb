{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "中文分词（HMM）",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaobingbing/AI-For-NLP/blob/master/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%EF%BC%88HMM%EF%BC%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xfUVuj-3uvL",
        "colab_type": "text"
      },
      "source": [
        "### HMM 建立中文分词模型，使用人们日报的分词语料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBs1kAg_3qHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e0be9772-619c-4263-a30b-8d8909349621"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MJKrFdW4EWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HMM(object):\n",
        "    def __init__(self):\n",
        "        import os\n",
        "    \n",
        "        # 用于存取算法中间结果，不用每次都训练模型\n",
        "        self.model_file = './drive/Shared drives/shao_bingbing/model/hmm_model.pkl'\n",
        "\n",
        "        # 状态值集合\n",
        "        # B: 单词的开头\n",
        "        # M: 单词的中间\n",
        "        # E: 单词的末尾\n",
        "        # S: 单独成词\n",
        "        self.state_list = ['B', 'M', 'E', 'S']\n",
        "\n",
        "        # 参数加载，用于判断是否需要重新加载model_file\n",
        "        self.load_para = False\n",
        "    \n",
        "    # 用于加载已计算的中间结果，当需要重新训练时，需初始化清空结果\n",
        "    def try_load_model(self, trained):\n",
        "        if trained:\n",
        "            import pickle\n",
        "            with open(self.model_file, 'rb') as f:\n",
        "                self.A_dic = pickle.load(f)\n",
        "                self.B_dic = pickle.load(f)\n",
        "                self.pi_dic = pickle.load(f)\n",
        "                self.load_para = True\n",
        "        \n",
        "        else:\n",
        "            # 状态转移概率：从上一个状态转移到下一个状态的概率 P(q_2|q_1)\n",
        "            self.A_dic = {}\n",
        "            # 发射概率 在该状态下对应观测值的概率 P(s_1|q_1)\n",
        "            self.B_dic = {}\n",
        "            # 状态的初始概率,对应相应的状态和概率\n",
        "            self.Pi_dic = {}\n",
        "            self.load_para = False\n",
        "        \n",
        "    # 计算转移概率、发射概率以及初始概率\n",
        "    def train(self, path):\n",
        "        self.try_load_model(False)\n",
        "        \n",
        "        #统计状态出现次数，求P(o)\n",
        "        Count_dic = {}\n",
        "        \n",
        "        #初始化参数\n",
        "        def init_parameter():\n",
        "            for state in self.state_list:\n",
        "                # 个数为n*n n为状态个数\n",
        "                self.A_dic[state] = {s: 0.0 for s in self.state_list}\n",
        "                # 初始状态概率，初始置为0\n",
        "                self.Pi_dic[state] = 0.0\n",
        "                # 发射概率,初始置为空字典，因为没有对应单词,找不到对应的键\n",
        "                self.B_dic[state] = {}\n",
        "                Count_dic[state] = 0\n",
        "                \n",
        "        def makeLabel(text):\n",
        "            # 对切分好的单词生成对应的标签\n",
        "            # 若单词长度为1，则为S，若为2，则为BS，多个以上BS中间使用M填充\n",
        "            out_text = []\n",
        "            if len(text) == 1:\n",
        "                out_text.append('S')\n",
        "            else:\n",
        "                out_text += ['B'] + ['M'] * (len(text) - 2) + ['E']\n",
        "                \n",
        "            return out_text\n",
        "        \n",
        "        init_parameter()\n",
        "        line_num = -1\n",
        "        \n",
        "        # 观察者集合，主要是字符以及标点\n",
        "        words = set()\n",
        "        with open(path, encoding = 'utf-8') as f:\n",
        "            for line in f:\n",
        "                line_num += 1\n",
        "                \n",
        "                # 去除两侧的空格\n",
        "                line = line.strip()\n",
        "                \n",
        "                # 跳过空行\n",
        "                if not line:\n",
        "                    continue\n",
        "                    \n",
        "                word_list = [i for i in line if i != ' ']\n",
        "                # 取集合的并集，保存了所有的字符，包括标点符号和特殊字符(如果存在的话，取决于语料库)\n",
        "                words |= set(word_list)\n",
        "                \n",
        "                # 分词语料库分词后的单词\n",
        "                linelist = line.split()\n",
        "                \n",
        "                line_state = []\n",
        "                for w in linelist:\n",
        "                    line_state.extend(makeLabel(w))\n",
        "                    \n",
        "#                 print(len(line_state), line_state)\n",
        "#                 print(len(word_list), word_list)\n",
        "                # word_list 和 line_state 分别对应该句话的观测值和状态值\n",
        "                assert len(word_list) == len(line_state)\n",
        "                \n",
        "                for k,v in enumerate(line_state):\n",
        "                    \n",
        "                    # 更新状态数目\n",
        "                    Count_dic[v] += 1\n",
        "                    \n",
        "                    if k == 0:\n",
        "                        # 每个句子的第一个字作为初始状态出现的次数\n",
        "                        self.Pi_dic[v] += 1\n",
        "                        \n",
        "                    else:\n",
        "                        # q_t和q_t+1出现的联合次数\n",
        "                        self.A_dic[line_state[k - 1]][v] += 1\n",
        "                        # 发射概率 P(S_k|q_k),需要对空字典进行更新操作，使用get(key, default_value)进行更新操作（如果该键不存在\n",
        "                        self.B_dic[line_state[k]][word_list[k]] = self.B_dic[line_state[k]].get(word_list[k], 0) + 1.0\n",
        "            \n",
        "                        \n",
        "        # 上面计算的为统计量，下面计算概率，范围(0,1)\n",
        "        # 更新初始状态概率，直接除以行数即可，有多少行代表以第一个出现了多少次\n",
        "        self.Pi_dic = {k: v*1.0/line_num for k,v in self.Pi_dic.items()}\n",
        "        \n",
        "        # 更新转移概率\n",
        "        self.A_dic = {k: {k1: v1/Count_dic[k] for k1,v1 in v.items()} for k, v in self.A_dic.items()}\n",
        "        \n",
        "        # 更新发射概率,加1平滑(在使用维特比算法进行计算可能会出现未知词，因此需要对其进行概率上的更新)\n",
        "        self.B_dict = {k: {k1: (v1 + 1)/Count_dic[k] for k1, v1 in v.items()} for k,v in self.B_dic.items()}\n",
        "        \n",
        "        import pickle\n",
        "        with open(self.model_file, 'wb') as f:\n",
        "            pickle.dump(self.A_dic, f)\n",
        "            pickle.dump(self.B_dic, f)\n",
        "            pickle.dump(self.Pi_dic, f)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    \n",
        "    def viterbi(self, text, states, start_p, trans_p, emit_p):\n",
        "        \n",
        "        # 保存第i步的最佳路径\n",
        "        V = [{}]\n",
        "        \n",
        "        path = {}\n",
        "        for y in states:\n",
        "            V[0][y] = start_p[y] * emit_p[y].get(text[0], 0)\n",
        "            path[y] = [y]\n",
        "        for t in range(1, len(text)):\n",
        "            V.append({})\n",
        "            newpath = {}\n",
        "            \n",
        "            #检验训练的发射概率矩阵中是否有该字\n",
        "            neverSeen = text[t] not in emit_p['S'].keys() and text[t] not in emit_p['M'].keys() and text[t] not in emit_p['E'].keys() and text[t] not in emit_p['B'].keys()\n",
        "            for y in states:\n",
        "                # 如果该单词未在语料库中出现\n",
        "                emitP = emit_p[y].get(text[t], 0) if not neverSeen else 1.0\n",
        "                (prob, state) = max([(V[t - 1][y0] * trans_p[y0].get(y, 0) *emitP, y0) for y0 in states if V[t - 1][y0] > 0])\n",
        "                V[t][y] = prob\n",
        "                newpath[y] = path[state] + [y]\n",
        "            path = newpath\n",
        "            \n",
        "        if emit_p['M'].get(text[-1], 0)> emit_p['S'].get(text[-1], 0):\n",
        "            (prob, state) = max([(V[len(text) - 1][y], y) for y in ('E','M')])\n",
        "        else:\n",
        "            (prob, state) = max([(V[len(text) - 1][y], y) for y in states])\n",
        "        \n",
        "        return (prob, path[state])\n",
        "    \n",
        "    def cut(self, text):\n",
        "        import os\n",
        "        if not self.load_para:\n",
        "            self.try_load_model(os.path.exists(self.model_file))\n",
        "        prob, pos_list = self.viterbi(text, self.state_list, self.Pi_dic, self.A_dic, self.B_dic)      \n",
        "        begin, next = 0, 0    \n",
        "        for i, char in enumerate(text):\n",
        "            pos = pos_list[i]\n",
        "            if pos == 'B':\n",
        "                begin = i\n",
        "            elif pos == 'E':\n",
        "                yield text[begin: i+1]\n",
        "                next = i+1\n",
        "            elif pos == 'S':\n",
        "                yield char\n",
        "                next = i+1\n",
        "        if next < len(text):\n",
        "            yield text[next:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh2WUKUuPuOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hmm = HMM()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSIiqhnVQLaD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8af3f90-e7a6-4d45-a12a-ebbabbc532c8"
      },
      "source": [
        "hmm.train('./drive/Shared drives/shao_bingbing/data/trainCorpus.txt')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.HMM at 0x7f4a2a1425c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wcBDxdjQYaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b0e74d6-3a96-454e-a12f-bbe4fc4875f5"
      },
      "source": [
        "text = '这是一个非常棒的方案！'\n",
        "res = hmm.cut(text)\n",
        "print(text)\n",
        "print(str(list(res)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "这是一个非常棒的方案！\n",
            "['这是', '一个', '非常', '棒', '的', '方案', '！']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-yVhuIa_bvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}